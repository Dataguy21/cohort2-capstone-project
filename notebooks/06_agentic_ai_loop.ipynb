{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7a3a2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent environment:\n",
      " - LangChain available: True\n",
      " - Agent memory available: True\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Agentic Loop - Start"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: c:\\Users\\mackrish_malik\\Desktop\\clinical-insights-assistant\\data\\clinical_trial_data.csv\n",
      "Loaded rows: 6000\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Detect Issues"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issue summary: {'non_compliance_count': 930, 'adverse_event_count': 623, 'outcome_anomaly_count': 102}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Train Scenario Simulator"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained regression model metrics: {'r2': 0.327, 'mae': 5.321}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Run Scenario Simulations"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario {'dosage_change': 10, 'compliance_change': 0} -> ΔOutcome = 1.59\n",
      "Scenario {'dosage_change': 0, 'compliance_change': 10} -> ΔOutcome = 2.81\n",
      "Scenario {'dosage_change': 10, 'compliance_change': 10} -> ΔOutcome = 4.32\n",
      "Scenario {'dosage_change': -10, 'compliance_change': -10} -> ΔOutcome = -4.16\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### GenAI Summaries"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Doctor Notes Summary (preview):**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here's a summary of the clinical doctor notes organized into the requested categories:\n",
      "\n",
      "**1. Key Observations:**\n",
      "\n",
      "*   Patient is currently stable.\n",
      "*   An adverse reaction was observed.\n",
      "*   Fatigue is present and being monitored.\n",
      "\n",
      "**2. Common Adverse Events:**\n",
      "\n",
      "*   Adverse reaction requiring dosage adjustment.\n",
      "*   Mild headache.\n",
      "*   Fatigue.\n",
      "\n",
      "**3. Positive Improvements:**\n",
      "\n",
      "*   Symptoms are improving with the current dosage (after adjustment presumably).\n",
      "\n",
      "**4. Outliers or Anomalies:**\n",
      "\n",
      "*   The \"adverse reaction\" is the most significant outlier since it necessitated a dosage adjustment. The nature and severity of this reaction would need further clarification from the full notes.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Regulatory Summary (preview):**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This randomized, controlled clinical trial involving 6,000 participants (Cohort A: 3,030, Cohort B: 2,970) investigated the efficacy and safety of a novel intervention. The study demonstrated a high level of compliance, with a mean compliance rate of 89.27% across both cohorts. Furthermore, participants exhibited a mean outcome score of 83.24, suggesting a positive impact on the measured outcome. These findings indicate potential clinical benefit associated with the intervention under study.\n",
      "\n",
      "The safety profile of the intervention was assessed through the monitoring of adverse events. During the trial, a total of 623 adverse events were reported. Further analysis is required to determine the severity, causality, and frequency of these events, including whether they are related to the intervention or other factors. A thorough evaluation of the adverse event data is crucial for a complete understanding of the intervention's safety profile.\n",
      "\n",
      "Overall, the trial results suggest a promising efficacy signal, evidenced by high compliance and a favorable mean outcome score. However, the occurrence of adverse events necessitates careful consideration. Further investigation, including detailed analysis of adverse event data and comparative analysis between cohorts, is warranted to fully characterize the benefit-risk profile of the intervention. These analyses will inform subsequent decisions regarding potential regulatory submissions and clinical implementation.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Generate Recommendations"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Recommendations:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-  Investigate patients with recorded adverse events; consider immediate follow-up.\n",
      "-  Run adherence interventions for patients below compliance threshold (e.g., reminders).\n",
      "-  Consider scenario with dosage change 10% and compliance change 10% — predicted avg outcome Δ = 4.32.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Agentic Loop - Completed"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent outputs keys: ['issues', 'simulator_metrics', 'scenarios', 'notes_summary', 'regulatory_summary', 'recommendations']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Agent Memory (recent entries)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'issues_summary': {'non_compliance_count': 930,\n",
       "   'adverse_event_count': 623,\n",
       "   'outcome_anomaly_count': 102}},\n",
       " {'simulator_metrics': {'r2': 0.327, 'mae': 5.321}},\n",
       " {'scenarios': [{'dosage_change': 10,\n",
       "    'compliance_change': 0,\n",
       "    'predicted_delta': np.float64(1.59)},\n",
       "   {'dosage_change': 0,\n",
       "    'compliance_change': 10,\n",
       "    'predicted_delta': np.float64(2.81)},\n",
       "   {'dosage_change': 10,\n",
       "    'compliance_change': 10,\n",
       "    'predicted_delta': np.float64(4.32)},\n",
       "   {'dosage_change': -10,\n",
       "    'compliance_change': -10,\n",
       "    'predicted_delta': np.float64(-4.16)}]},\n",
       " {'notes_summary': 'Okay, here\\'s a summary of the clinical doctor notes organized into the requested categories:\\n\\n**1. Key Observations:**\\n\\n*   Patient is currently stable.\\n*   An adverse reaction was observed.\\n*   Fatigue is present and being monitored.\\n\\n**2. Common Adverse Events:**\\n\\n*   Adverse reaction requiring dosage adjustment.\\n*   Mild headache.\\n*   Fatigue.\\n\\n**3. Positive Improvements:**\\n\\n*   Symptoms are improving with the current dosage (after adjustment presumably).\\n\\n**4. Outliers or Anomalies:**\\n\\n*   The \"adverse reaction\" is the most significant outlier since it necessitated a dosage adjustment. The nature and severity of this reaction would need further clarification from the full notes.',\n",
       "  'regulatory_summary': \"This randomized, controlled clinical trial involving 6,000 participants (Cohort A: 3,030, Cohort B: 2,970) investigated the efficacy and safety of a novel intervention. The study demonstrated a high level of compliance, with a mean compliance rate of 89.27% across both cohorts. Furthermore, participants exhibited a mean outcome score of 83.24, suggesting a positive impact on the measured outcome. These findings indicate potential clinical benefit associated with the intervention under study.\\n\\nThe safety profile of the intervention was assessed through the monitoring of adverse events. During the trial, a total of 623 adverse events were reported. Further analysis is required to determine the severity, causality, and frequency of these events, including whether they are related to the intervention or other factors. A thorough evaluation of the adverse event data is crucial for a complete understanding of the intervention's safety profile.\\n\\nOverall, the trial results suggest a promising efficacy signal, evidenced by high compliance and a favorable mean outcome score. However, the occurrence of adverse events necessitates careful consideration. Further investigation, including detailed analysis of adverse event data and comparative analysis between cohorts, is warranted to fully characterize the benefit-risk profile of the intervention. These analyses will inform subsequent decisions regarding potential regulatory submissions and clinical implementation.\"},\n",
       " {'recommendations': ['Investigate patients with recorded adverse events; consider immediate follow-up.',\n",
       "   'Run adherence interventions for patients below compliance threshold (e.g., reminders).',\n",
       "   'Consider scenario with dosage change 10% and compliance change 10% — predicted avg outcome Δ = 4.32.']}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Agentic loop finished. You can save outputs or extend the agent to run automatically on schedule."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "notebooks/06_agentic_ai_loop.ipynb\n",
    "Agentic AI Loop - Capstone 3\n",
    "--------------------------------\n",
    "Purpose:\n",
    " - Demonstrate an agent that orchestrates data analysis tasks:\n",
    "   1) Load dataset\n",
    "   2) Run issue detection\n",
    "   3) Train & run simulation\n",
    "   4) Call GenAI for summaries\n",
    "   5) Produce recommendations\n",
    "\n",
    "Notes:\n",
    " - This notebook uses your existing src/ modules:\n",
    "   src/data_loader.py, src/issue_detection.py, src/scenario_simulation.py,\n",
    "   src/genai_interface.py, src/agent/memory.py (optional)\n",
    " - If LangChain is available it shows an example integration; otherwise it runs a safe local agent.\n",
    "\"\"\"\n",
    "\n",
    "# -------------------- Imports & Setup --------------------\n",
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# make src importable\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../src\")))\n",
    "\n",
    "# core tools from src\n",
    "from data_loader import load_csv\n",
    "from issue_detection import detect_non_compliance, detect_adverse_events, detect_outcome_anomalies, summarize_issues\n",
    "from scenario_simulation import train_simulation_model, simulate_scenario\n",
    "from genai_interface import summarize_doctor_notes, generate_regulatory_summary\n",
    "\n",
    "# optional agent memory\n",
    "try:\n",
    "    from agent.memory import Memory\n",
    "    have_memory = True\n",
    "except Exception:\n",
    "    have_memory = False\n",
    "\n",
    "# Try to import langchain for optional advanced agent (not required)\n",
    "try:\n",
    "    from langchain import LLMChain, PromptTemplate\n",
    "    from langchain.llms import OpenAI  # this is optional; only for demonstration\n",
    "    have_langchain = True\n",
    "except Exception:\n",
    "    have_langchain = False\n",
    "\n",
    "print(\"Agent environment:\")\n",
    "print(\" - LangChain available:\", have_langchain)\n",
    "print(\" - Agent memory available:\", have_memory)\n",
    "\n",
    "# -------------------- Helper utilities --------------------\n",
    "\n",
    "def get_data_path():\n",
    "    # robust path detection (works in notebook and script)\n",
    "    project_root = os.getcwd()\n",
    "    if \"notebooks\" in project_root:\n",
    "        return os.path.abspath(os.path.join(project_root, \"../data/clinical_trial_data.csv\"))\n",
    "    return os.path.abspath(os.path.join(project_root, \"data/clinical_trial_data.csv\"))\n",
    "\n",
    "def load_data():\n",
    "    path = get_data_path()\n",
    "    print(\"Loading data from:\", path)\n",
    "    df = pd.read_csv(path, parse_dates=[\"visit_date\"])\n",
    "    df.columns = [c.strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
    "    return df\n",
    "\n",
    "def pretty_section(title):\n",
    "    display(Markdown(f\"### {title}\"))\n",
    "\n",
    "# -------------------- Agent Implementation --------------------\n",
    "\n",
    "class SimpleAgent:\n",
    "    \"\"\"\n",
    "    Deterministic local agent that orchestrates analysis steps.\n",
    "    Uses the src modules (issue detection, simulation, genai) and optional memory.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, memory=None):\n",
    "        self.df = df\n",
    "        self.memory = memory\n",
    "        self.outputs = {}\n",
    "\n",
    "    def step_detect_issues(self, compliance_threshold=80):\n",
    "        pretty_section(\"Detect Issues\")\n",
    "        non_comp = detect_non_compliance(self.df, threshold=compliance_threshold)\n",
    "        adverse = detect_adverse_events(self.df)\n",
    "        anomalies = detect_outcome_anomalies(self.df)\n",
    "        summary = {\n",
    "            \"non_compliance_count\": len(non_comp),\n",
    "            \"adverse_event_count\": len(adverse),\n",
    "            \"outcome_anomaly_count\": len(anomalies)\n",
    "        }\n",
    "        self.outputs[\"issues\"] = {\n",
    "            \"non_compliant\": non_comp,\n",
    "            \"adverse\": adverse,\n",
    "            \"anomalies\": anomalies,\n",
    "            \"summary\": summary\n",
    "        }\n",
    "        print(\"Issue summary:\", summary)\n",
    "        if self.memory is not None:\n",
    "            self.memory.add({\"issues_summary\": summary})\n",
    "        return summary\n",
    "\n",
    "    def step_train_simulator(self):\n",
    "        pretty_section(\"Train Scenario Simulator\")\n",
    "        try:\n",
    "            metrics = train_simulation_model(self.df)\n",
    "            self.outputs[\"simulator_metrics\"] = metrics\n",
    "            print(\"Trained regression model metrics:\", metrics)\n",
    "            if self.memory is not None:\n",
    "                self.memory.add({\"simulator_metrics\": metrics})\n",
    "            return metrics\n",
    "        except Exception as e:\n",
    "            print(\"Simulator training failed:\", e)\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "    def step_run_scenarios(self, scenarios=None):\n",
    "        pretty_section(\"Run Scenario Simulations\")\n",
    "        if scenarios is None:\n",
    "            scenarios = [\n",
    "                {\"dosage_change\": 10, \"compliance_change\": 0},\n",
    "                {\"dosage_change\": 0, \"compliance_change\": 10},\n",
    "                {\"dosage_change\": 10, \"compliance_change\": 10},\n",
    "                {\"dosage_change\": -10, \"compliance_change\": -10},\n",
    "            ]\n",
    "        results = []\n",
    "        for s in scenarios:\n",
    "            try:\n",
    "                delta = simulate_scenario(s[\"dosage_change\"], s[\"compliance_change\"], self.df)\n",
    "                results.append({**s, \"predicted_delta\": delta})\n",
    "                print(f\"Scenario {s} -> ΔOutcome = {delta}\")\n",
    "            except Exception as e:\n",
    "                results.append({**s, \"error\": str(e)})\n",
    "                print(\"Scenario error:\", e)\n",
    "        self.outputs[\"scenarios\"] = results\n",
    "        if self.memory is not None:\n",
    "            self.memory.add({\"scenarios\": results})\n",
    "        return results\n",
    "\n",
    "    def step_genai_summaries(self, notes_limit=200):\n",
    "        pretty_section(\"GenAI Summaries\")\n",
    "        notes = self.df.get(\"doctor_notes\", pd.Series([], dtype=object)).dropna().unique().tolist()[:notes_limit]\n",
    "        if not notes:\n",
    "            print(\"No doctor notes found in dataset to summarize.\")\n",
    "            notes_summary = \"No doctor notes available.\"\n",
    "        else:\n",
    "            try:\n",
    "                notes_summary = summarize_doctor_notes(notes)\n",
    "            except Exception as e:\n",
    "                notes_summary = f\"GenAI summarization failed: {e}\"\n",
    "        # Regulatory summary: auto-compose trial text\n",
    "        trial_text_parts = []\n",
    "        trial_text_parts.append(f\"Rows: {len(self.df)}\")\n",
    "        if \"cohort\" in self.df.columns:\n",
    "            trial_text_parts.append(f\"Cohorts: {self.df['cohort'].value_counts().to_dict()}\")\n",
    "        if \"compliance_pct\" in self.df.columns or \"compliance_rate\" in self.df.columns:\n",
    "            col = \"compliance_pct\" if \"compliance_pct\" in self.df.columns else \"compliance_rate\"\n",
    "            trial_text_parts.append(f\"Mean compliance: {self.df[col].mean():.2f}\")\n",
    "        if \"adverse_event_flag\" in self.df.columns or \"adverse_event\" in self.df.columns:\n",
    "            a_col = \"adverse_event_flag\" if \"adverse_event_flag\" in self.df.columns else \"adverse_event\"\n",
    "            trial_text_parts.append(f\"Adverse event count: {int(self.df[a_col].sum())}\")\n",
    "        if \"outcome_score\" in self.df.columns:\n",
    "            trial_text_parts.append(f\"Mean outcome score: {self.df['outcome_score'].mean():.2f}\")\n",
    "        trial_text = \"\\n\".join(trial_text_parts)\n",
    "        try:\n",
    "            regulatory_summary = generate_regulatory_summary(trial_text)\n",
    "        except Exception as e:\n",
    "            regulatory_summary = f\"Regulatory summary generation failed: {e}\"\n",
    "\n",
    "        self.outputs[\"notes_summary\"] = notes_summary\n",
    "        self.outputs[\"regulatory_summary\"] = regulatory_summary\n",
    "\n",
    "        # show small preview\n",
    "        display(Markdown(\"**Doctor Notes Summary (preview):**\"))\n",
    "        print(notes_summary[:2000] + (\"...\" if len(notes_summary) > 2000 else \"\"))\n",
    "        display(Markdown(\"**Regulatory Summary (preview):**\"))\n",
    "        print(regulatory_summary[:2000] + (\"...\" if len(regulatory_summary) > 2000 else \"\"))\n",
    "\n",
    "        if self.memory is not None:\n",
    "            self.memory.add({\"notes_summary\": notes_summary, \"regulatory_summary\": regulatory_summary})\n",
    "\n",
    "        return {\"notes_summary\": notes_summary, \"regulatory_summary\": regulatory_summary}\n",
    "\n",
    "    def step_recommendations(self):\n",
    "        pretty_section(\"Generate Recommendations\")\n",
    "        recs = []\n",
    "        issues = self.outputs.get(\"issues\", {}).get(\"summary\", {})\n",
    "        scenarios = self.outputs.get(\"scenarios\", [])\n",
    "        # High-level rules to create recommendations\n",
    "        if issues.get(\"adverse_event_count\", 0) > 0:\n",
    "            recs.append(\"Investigate patients with recorded adverse events; consider immediate follow-up.\")\n",
    "        if issues.get(\"non_compliance_count\", 0) > 0:\n",
    "            recs.append(\"Run adherence interventions for patients below compliance threshold (e.g., reminders).\")\n",
    "        # Use scenario outputs to recommend dosage/compliance actions\n",
    "        best = None\n",
    "        for s in scenarios:\n",
    "            if \"predicted_delta\" in s:\n",
    "                if best is None or s[\"predicted_delta\"] > best[\"predicted_delta\"]:\n",
    "                    best = s\n",
    "        if best and best.get(\"predicted_delta\", 0) > 0:\n",
    "            recs.append(f\"Consider scenario with dosage change {best['dosage_change']}% and compliance change {best['compliance_change']}% — predicted avg outcome Δ = {best['predicted_delta']}.\")\n",
    "        if not recs:\n",
    "            recs.append(\"No immediate actions suggested; continue monitoring and run scheduled analyses.\")\n",
    "\n",
    "        self.outputs[\"recommendations\"] = recs\n",
    "        if self.memory is not None:\n",
    "            self.memory.add({\"recommendations\": recs})\n",
    "\n",
    "        display(Markdown(\"**Recommendations:**\"))\n",
    "        for r in recs:\n",
    "            print(\"- \", r)\n",
    "        return recs\n",
    "\n",
    "    def run_full_loop(self):\n",
    "        # Orchestrate all steps in order\n",
    "        self.step_detect_issues()\n",
    "        self.step_train_simulator()\n",
    "        self.step_run_scenarios()\n",
    "        self.step_genai_summaries()\n",
    "        self.step_recommendations()\n",
    "        return self.outputs\n",
    "\n",
    "# -------------------- Run the Agent --------------------\n",
    "pretty_section(\"Agentic Loop - Start\")\n",
    "\n",
    "# Load data\n",
    "df = load_data()\n",
    "print(\"Loaded rows:\", len(df))\n",
    "\n",
    "# Create memory if available\n",
    "memory = Memory() if have_memory else None\n",
    "\n",
    "agent = SimpleAgent(df=df, memory=memory)\n",
    "outputs = agent.run_full_loop()\n",
    "\n",
    "pretty_section(\"Agentic Loop - Completed\")\n",
    "print(\"Agent outputs keys:\", list(outputs.keys()))\n",
    "\n",
    "# If memory was used, show last stored items\n",
    "if memory is not None:\n",
    "    pretty_section(\"Agent Memory (recent entries)\")\n",
    "    display(memory.get_all()[-5:])  # show last 5 entries\n",
    "\n",
    "# -------------------- End of notebook --------------------\n",
    "display(Markdown(\"#### Agentic loop finished. You can save outputs or extend the agent to run automatically on schedule.\"))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
